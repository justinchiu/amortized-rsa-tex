@inproceedings{obermeyer2019tve,
  author    = {Fritz Obermeyer and
               Eli Bingham and
               Martin Jankowiak and
               Neeraj Pradhan and
               Justin Chiu and
               Alexander M. Rush and
               Noah D. Goodman},
  editor    = {Kamalika Chaudhuri and
               Ruslan Salakhutdinov},
  title     = {Tensor Variable Elimination for Plated Factor Graphs},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning,
               {ICML} 2019, 9-15 June 2019, Long Beach, California, {USA}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {97},
  pages     = {4871--4880},
  publisher = {{PMLR}},
  year      = {2019},
  url       = {http://proceedings.mlr.press/v97/obermeyer19a.html},
  timestamp = {Fri, 28 Feb 2020 11:29:46 +0100},
  biburl    = {https://dblp.org/rec/conf/icml/ObermeyerBJPCRG19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{vieira2014gumbel,
    title = "Gumbel-max trick and weighted reservoir sampling",
    author = "Vieira, Tim",
    year = "2014",
    url = "https://timvieira.github.io/blog/post/2014/08/01/gumbel-max-trick-and-weighted-reservoir-sampling",
}

@misc{zaslavsky2020ratedistortion,
      title={A Rate-Distortion view of human pragmatic reasoning}, 
      author={Noga Zaslavsky and Jennifer Hu and Roger P. Levy},
      year={2020},
      eprint={2005.06641},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{mcdowell2019learning,
    title = "Learning from Omission",
    author = "McDowell, Bill  and
      Goodman, Noah",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1059",
    doi = "10.18653/v1/P19-1059",
    pages = "619--628",
    abstract = "Pragmatic reasoning allows humans to go beyond the literal meaning when interpret- ing language in context. Previous work has shown that such reasoning can improve the performance of already-trained language understanding systems. Here, we explore whether pragmatic reasoning during training can improve the quality of learned meanings. Our experiments on reference game data show that end-to-end pragmatic training produces more accurate utterance interpretation models, especially when data is sparse and language is complex.",
}

@misc{gulordava2020dax,
      title={Which one is the dax? Achieving mutual exclusivity with neural networks}, 
      author={Kristina Gulordava and Thomas Brochhagen and Gemma Boleda},
      year={2020},
      eprint={2004.03902},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{white2020learning,
      title={Learning to refer informatively by amortizing pragmatic reasoning}, 
      author={Julia White and Jesse Mu and Noah D. Goodman},
      year={2020},
      eprint={2006.00418},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{cohngordon2018pragmatically,
      title={Pragmatically Informative Image Captioning with Character-Level Inference}, 
      author={Reuben Cohn-Gordon and Noah Goodman and Christopher Potts},
      year={2018},
      eprint={1804.05417},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{belanger2016structured,
      title={Structured Prediction Energy Networks}, 
      author={David Belanger and Andrew McCallum},
      year={2016},
      eprint={1511.06350},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{gu2017trainable,
      title={Trainable Greedy Decoding for Neural Machine Translation}, 
      author={Jiatao Gu and Kyunghyun Cho and Victor O. K. Li},
      year={2017},
      eprint={1702.02429},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
